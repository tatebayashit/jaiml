## ğŸ“˜ JAIML Unified Specification v1.0ï¼ˆçµ±åˆä»•æ§˜æ›¸ï¼‰- æ”¹è¨‚ç‰ˆ

### A. çµ±ä¸€è¨˜è¿°ã‚»ã‚¯ã‚·ãƒ§ãƒ³

#### A.1 æ¦‚è¦

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: JAIML (Japanese AI Ingratiation Modeling Layer) çµ±åˆã‚·ã‚¹ãƒ†ãƒ 

**ç›®çš„**: æœ¬ä»•æ§˜æ›¸ã¯ã€JAIMLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹æˆè¦ç´ ã§ã‚ã‚‹ä»¥ä¸‹ã®3ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ•´åˆæ€§ã¨é€£æºæ–¹æ³•ã‚’å®šã‚ã‚‹ï¼š

* **JAIML v3.3**ï¼šè‡ªå·±å‘ˆç¤ºãƒ»è¿åˆæ€§åˆ†é¡å™¨ã®æœ¬ä½“ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒ¢ãƒ‡ãƒ«å±¤ï¼‰
* **lexicon_expansion v2.0**ï¼šè¾æ›¸æ‹¡å¼µãƒ»ã‚¹ã‚³ã‚¢æŠ½å‡ºæ©Ÿæ§‹ï¼ˆè¾æ›¸å±¤ï¼‰
* **vector_pretrainer v1.1**ï¼šã‚³ãƒ¼ãƒ‘ã‚¹ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«äº‹å‰å­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹å±¤ï¼‰

**åŸºæœ¬æ–¹é‡**: å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å…±é€šè¨­å®šä½“ç³»ï¼ˆ`config/global.yaml`ï¼‰ã«æº–æ‹ ã—ã€çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚Šç›¸äº’é€£æºã™ã‚‹ã€‚

#### A.2 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã¨è²¬å‹™

```plaintext
src/
â”œâ”€â”€ ci/                           # CI/CDæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¾¤
â”‚   â”œâ”€â”€ schema_validate.py        # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
â”‚   â”œâ”€â”€ check_tokenizer.py        # tokenizerçµ±ä¸€æ€§æ¤œæŸ»
â”‚   â””â”€â”€ check_versions.py         # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§æ¤œæŸ»
â”œâ”€â”€ config/                       # å…±é€šè¨­å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”‚   â”œâ”€â”€ global.yaml              # å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å…±é€šè¨­å®š
â”‚   â””â”€â”€ tfidf_config.yaml        # TF-IDFå°‚ç”¨è¨­å®š
â”œâ”€â”€ lexicon_expansion/            # è¾æ›¸æ‹¡å¼µãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ jaiml_v3_3/              # JAIMLæœ¬ä½“
â”‚   â””â”€â”€ vectorizers/             # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ™ã‚¯ãƒˆãƒ«æ ¼ç´
â”‚       â”œâ”€â”€ tfidf_vectorizer.joblib
â”‚       â””â”€â”€ metadata.json
â”œâ”€â”€ vector_pretrainer/            # ãƒ™ã‚¯ãƒˆãƒ«äº‹å‰å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â””â”€â”€ requirements.txt              # ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå®šç¾©
```

**å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è²¬å‹™**:

1. **vector_pretrainer v1.1**
   - å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰TF-IDFãƒ™ã‚¯ãƒˆãƒ«ã‚’å­¦ç¿’ãƒ»ä¿å­˜
   - ã‚³ãƒ¼ãƒ‘ã‚¹ã®å‰å‡¦ç†ã¨JSONLå½¢å¼ã¸ã®çµ±ä¸€
   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

2. **JAIML v3.3**
   - 12æ¬¡å…ƒç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã€4ã‚«ãƒ†ã‚´ãƒªã®è¿åˆæ€§ã‚’åˆ†é¡
   - äº‹å‰å­¦ç¿’æ¸ˆã¿TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’æ´»ç”¨
   - çµ±åˆçš„ãªè¿åˆæ€§åˆ†æã®å®Ÿè¡Œ

3. **lexicon_expansion v2.0**
   - è¾æ›¸ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ»èªå½™æ‹¡å¼µ
   - å¼±æ•™å¸«ä»˜ãå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
   - è¾æ›¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨å·®åˆ†è¿½è·¡

#### A.3 å…¥å‡ºåŠ›ä»•æ§˜

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®å…¥åŠ›**:
1. å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆJSONLå½¢å¼ï¼‰
2. èªå½™è¾æ›¸ï¼ˆYAMLå½¢å¼ï¼‰
3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ï¼ˆYAMLå½¢å¼ï¼‰

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®å‡ºåŠ›**:
1. è¿åˆæ€§åˆ†æçµæœï¼ˆJSONå½¢å¼ï¼‰
2. å­¦ç¿’æ¸ˆã¿TF-IDFãƒ¢ãƒ‡ãƒ«ï¼ˆjoblibå½¢å¼ï¼‰
3. æ‹¡å¼µèªå½™è¾æ›¸ï¼ˆYAMLå½¢å¼ï¼‰
4. å¼±æ•™å¸«ä»˜ãå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONLå½¢å¼ï¼‰

**æ¨™æº–JSONLã‚¹ã‚­ãƒ¼ãƒ**:
```json
{
  "user": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆ",
  "response": "AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ",
  "metadata": {
    "source": "ã‚³ãƒ¼ãƒ‘ã‚¹å",
    "timestamp": "ISO8601å½¢å¼",
    "topic": "è©±é¡Œã‚«ãƒ†ã‚´ãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
    "anonymized": true,
    "anonymizer_version": "ginza-5.3.0",
    "verified_by_human": true
  }
}
```

#### A.4 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©

**å…±é€šç”¨èªå®šç¾©**:

| ç”¨èª | å®šç¾© | å€¤/å½¢å¼ | ä½¿ç”¨ç®‡æ‰€ |
|------|------|---------|----------|
| `tokenizer` | å½¢æ…‹ç´ è§£æå™¨ã®æŒ‡å®š | å›ºå®šå€¤: `"fugashi"` | å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« |
| `min_df` | TF-IDFè¨ˆç®—æ™‚ã®æœ€å°æ–‡æ›¸é »åº¦é–¾å€¤ | æ•´æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰ | vector_pretrainer, JAIML |
| `max_df` | TF-IDFè¨ˆç®—æ™‚ã®æœ€å¤§æ–‡æ›¸é »åº¦é–¾å€¤ | å®Ÿæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.95ï¼‰ | vector_pretrainer, JAIML |
| `ngram_range` | N-gramã®ç¯„å›²æŒ‡å®š | ãƒªã‚¹ãƒˆï¼ˆä¾‹: `[1, 1]`ï¼‰ | å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« |
| `vectorizer_path` | å­¦ç¿’æ¸ˆã¿TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã®ä¿å­˜ãƒ‘ã‚¹ | æ–‡å­—åˆ— | JAIML, lexicon_expansion |
| `lexicon_path` | èªå½™è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ | æ–‡å­—åˆ— | JAIML, lexicon_expansion |
| `encoding` | æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° | å›ºå®šå€¤: `"utf-8"` | å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« |
| `canonical_key` | è¾æ›¸ã‚¨ãƒ³ãƒˆãƒªã®æ­£è¦åŒ–ã‚­ãƒ¼ | æ–‡å­—åˆ—ï¼ˆNFKCæ­£è¦åŒ–æ¸ˆã¿ï¼‰ | lexicon_expansion |
| `novelty_top_k` | TF-IDFæ–°è¦æ€§ä¸Šä½é–¾å€¤ | å®Ÿæ•°ï¼ˆ0.0-1.0ï¼‰ | lexicon_expansion |

**å…±é€šè¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆconfig/global.yamlï¼‰**:
```yaml
common:
  tokenizer: fugashi
  encoding: utf-8
  
tfidf:
  min_df: 1
  max_df: 0.95
  ngram_range: [1, 1]
  
paths:
  vectorizer_path: model/vectorizers/tfidf_vectorizer.joblib
  lexicon_path: lexicons/jaiml_lexicons.yaml
```

#### A.5 é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**:
```
config/
â”œâ”€â”€ global.yaml              # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±é€šè¨­å®š
â”œâ”€â”€ tfidf_config.yaml        # TF-IDFå°‚ç”¨è¨­å®š
â””â”€â”€ schemas/                 # YAMLã‚¹ã‚­ãƒ¼ãƒå®šç¾©
    â”œâ”€â”€ global_schema.yaml
    â”œâ”€â”€ tfidf_schema.yaml
    â””â”€â”€ category_schema.yaml # ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚­ãƒ¼ãƒå®šç¾©
```

**ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«**:
```
lexicons/
â”œâ”€â”€ jaiml_lexicons.yaml      # ãƒã‚¹ã‚¿ãƒ¼èªå½™è¾æ›¸
â””â”€â”€ versions/                # ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´
    â””â”€â”€ changelog.json

model/vectorizers/
â”œâ”€â”€ tfidf_vectorizer.joblib  # å­¦ç¿’æ¸ˆã¿TF-IDFãƒ¢ãƒ‡ãƒ«
â””â”€â”€ metadata.json            # ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

corpus/
â”œâ”€â”€ raw/                     # ç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹
â””â”€â”€ jsonl/                   # æ­£è¦åŒ–æ¸ˆã¿ã‚³ãƒ¼ãƒ‘ã‚¹
```

**å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«**:
```
outputs/
â”œâ”€â”€ analysis_results/        # è¿åˆæ€§åˆ†æçµæœ
â”œâ”€â”€ weak_supervised/         # å¼±æ•™å¸«ãƒ‡ãƒ¼ã‚¿
â””â”€â”€ reports/                 # å„ç¨®ãƒ¬ãƒãƒ¼ãƒˆ
```

#### A.6 ä½¿ç”¨ä¾‹ã¨ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³

**çµ±åˆå®Ÿè¡Œä¾‹**:
```bash
# 1. ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’å­¦ç¿’
python src/vector_pretrainer/scripts/train_tfidf.py \
  --corpus corpus/jsonl/combined.jsonl \
  --config config/tfidf_config.yaml \
  --output model/vectorizers/

# 2. è¾æ›¸æ‹¡å¼µã®å®Ÿè¡Œ
python src/lexicon_expansion/scripts/run_expansion.py \
  --phase extract \
  --corpus corpus/jsonl/dialogue.jsonl \
  --output outputs/candidates/

# 3. JAIMLåˆ†æã®å®Ÿè¡Œ
python src/model/jaiml_v3_3/scripts/run_inference.py \
  --input data/test_dialogues.jsonl \
  --output outputs/analysis_results/results.jsonl \
  --lexicon lexicons/jaiml_lexicons.yaml \
  --vectorizer model/vectorizers/tfidf_vectorizer.joblib

# 4. å¼±æ•™å¸«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
python src/lexicon_expansion/scripts/run_advanced_features.py \
  --feature annotate \
  --corpus corpus/jsonl/dialogue.jsonl \
  --output outputs/weak_supervised/training_data.jsonl

# 5. åŒ¿ååŒ–å‡¦ç†ã®å®Ÿè¡Œä¾‹
python src/vector_pretrainer/scripts/anonymize.py \
  --input corpus/raw/dialogue.jsonl \
  --output corpus/anonymized/dialogue.jsonl \
  --model ja_ginza_electra \
  --human-review-output corpus/review/dialogue_review.csv
```

**CIæ¤œè¨¼ã®å®Ÿè¡Œ**:
```bash
# å…¨æ¤œè¨¼ã‚’å®Ÿè¡Œ
python src/ci/run_all_checks.py --output-format json

# å€‹åˆ¥æ¤œè¨¼
python src/ci/schema_validate.py
python src/ci/check_tokenizer.py
python src/ci/check_versions.py
```

#### A.7 CIæ¤œè¨¼é …ç›®

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¨ªæ–­çš„ãªæ¤œè¨¼é …ç›®**:

| æ¤œè¨¼é …ç›® | å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ | æ¤œè¨¼å†…å®¹ | å¤±æ•—æ¡ä»¶ |
|----------|---------------|----------|----------|
| YAMLè¨­å®šæ•´åˆæ€§ | `ci/schema_validate.py` | global.yamlã¨tfidf_config.yamlã®å€¤ã®ä¸€è‡´ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã®ä¸ä¸€è‡´ |
| ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼æ•´åˆæ€§ | `ci/check_versions.py` | metadata.jsonã¨sklearn_versionã®ç¢ºèª | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´ |
| tokenizerçµ±ä¸€æ€§ | `ci/check_tokenizer.py` | å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§fugashiä½¿ç”¨ | fugashiä»¥å¤–ã®æ¤œå‡º |
| JSONLå½¢å¼æ¤œè¨¼ | `ci/check_jsonl.py` | user/responseãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ | å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ å¦‚ |
| ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ•´åˆæ€§ | `ci/check_dependencies.py` | requirements.txtã¨ã®ç…§åˆ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¯„å›²å¤– |
| è¾æ›¸å®Œå…¨æ€§ | `ci/check_lexicon.py` | 11ã‚«ãƒ†ã‚´ãƒªã®å­˜åœ¨ç¢ºèª | ã‚«ãƒ†ã‚´ãƒªæ¬ å¦‚ |
| è¾æ›¸ã‚¨ãƒ³ãƒˆãƒªé‡è¤‡ | `ci/check_lexicon.py` | ã‚«ãƒ†ã‚´ãƒªæ¨ªæ–­ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ | canonical_keyé‡è¤‡ |
| è¾æ›¸ãƒãƒƒã‚·ãƒ¥æ•´åˆæ€§ | `ci/check_lexicon_hash.py` | changelogã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ | ä¸ä¸€è‡´ |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œæŸ» | `ci/check_security.py` | Pickleä½¿ç”¨ãƒ»è„†å¼±æ€§æ¤œå‡º | è­¦å‘Šãªã—Pickleä½¿ç”¨ |

**GitHub Actionsçµ±åˆ**:
```yaml
name: JAIML CI

on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: pip install -r src/requirements.txt
      - name: Run all validations
        run: python src/ci/run_all_checks.py
      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: ci-reports
          path: ci/reports/
```

#### A.8 ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©ï¼ˆå‹æ³¨é‡ˆä»˜ãï¼‰

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±é€šã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**:

```python
from typing import Dict, List, Any, Optional
from pathlib import Path

# è¨­å®šç®¡ç†
class ConfigManager:
    def __init__(self, config_path: str = "config/global.yaml"):
        """å…±é€šè¨­å®šã®èª­ã¿è¾¼ã¿"""
    
    def get_tfidf_config(self) -> Dict[str, Any]:
        """TF-IDFè¨­å®šã®å–å¾—"""
    
    def get_paths(self) -> Dict[str, Path]:
        """ãƒ‘ã‚¹è¨­å®šã®å–å¾—"""

# TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ç®¡ç†
class TFIDFNoveltyCalculator:
    def load_model(self, path: str) -> None:
        """
        äº‹å‰å­¦ç¿’æ¸ˆã¿TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            path: .joblibãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Raises:
            RuntimeError: sklearn_versionãŒä¸ä¸€è‡´ã®å ´åˆ
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """

# è¿åˆæ€§åˆ†æçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
class JAIMLAnalyzer:
    def __init__(self, model_path: str, lexicon_path: str, 
                 vectorizer_path: str, config_path: str = "config/global.yaml"):
        """
        çµ±åˆåˆ†æå™¨ã®åˆæœŸåŒ–
        
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            lexicon_path: èªå½™è¾æ›¸ã®ãƒ‘ã‚¹
            vectorizer_path: TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã®ãƒ‘ã‚¹
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
    
    def analyze(self, user: str, response: str) -> Dict[str, Any]:
        """
        å¯¾è©±ãƒšã‚¢ã‹ã‚‰è¿åˆæ€§ã‚’åˆ†æ
        
        Returns:
            Dict: {
                "input": å…¥åŠ›å¯¾è©±ãƒšã‚¢,
                "scores": 4ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢,
                "index": çµ±åˆè¿åˆåº¦,
                "predicted_category": ä¸»ã‚«ãƒ†ã‚´ãƒª,
                "features": 12æ¬¡å…ƒç‰¹å¾´é‡,
                "meta": ãƒ¡ã‚¿æƒ…å ±
            }
        """
    
    def analyze_batch(self, input_path: str, output_path: str) -> None:
        """ãƒãƒƒãƒåˆ†æã®å®Ÿè¡Œ"""

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ãƒ‡ãƒ¼ã‚¿äº¤æ›
class DataExchange:
    @staticmethod
    def validate_jsonl(file_path: str) -> bool:
        """JSONLå½¢å¼ã®æ¤œè¨¼"""
    
    @staticmethod
    def convert_to_jsonl(input_path: str, output_path: str, 
                        format: str = "plaintext") -> int:
        """å„ç¨®å½¢å¼ã‚’JSONLå½¢å¼ã«å¤‰æ›"""
```

#### A.9 æ—¢çŸ¥ã®åˆ¶ç´„ã¨æ³¨æ„äº‹é …

**ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®åˆ¶ç´„**:
1. **Pythonç‰ˆ**: 3.8ã€œ3.11ã®ã¿ã‚µãƒãƒ¼ãƒˆ
2. **OS**: Ubuntu 20.04/22.04ã§å®Œå…¨ãƒ†ã‚¹ãƒˆæ¸ˆã¿
3. **ãƒ¡ãƒ¢ãƒª**: å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒæ™‚å®Ÿè¡Œæ™‚ã¯8GBä»¥ä¸Šæ¨å¥¨
4. **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: TF-IDFãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€å¤§200MBï¼‰+ ã‚³ãƒ¼ãƒ‘ã‚¹å®¹é‡
5. **å®Ÿè¡Œæ™‚é–“**: 100ä¸‡æ–‡æ›¸ã®å®Œå…¨å‡¦ç†ã«ç´„4æ™‚é–“

**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®æ³¨æ„**:
1. **Pickleç¦æ­¢**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®ãŸã‚ä½¿ç”¨ç¦æ­¢
2. **joblibæ¨å¥¨**: compress=3ã§ã®ä¿å­˜ã‚’æ¨å¥¨
3. **ãƒ‡ãƒ¼ã‚¿åŒ¿ååŒ–**: 2æ®µéšå‡¦ç†ã«ã‚ˆã‚‹å€‹äººæƒ…å ±ã®ç¢ºå®Ÿãªé™¤å»
   - (a) è‡ªå‹•å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚º: GiNZA (ja_ginza_electra) ã«ã‚ˆã‚‹NER + æ­£è¦è¡¨ç¾
   - (b) äººæ‰‹è£œå®Œãƒ•ã‚§ãƒ¼ã‚º: Spreadsheet/å°‚ç”¨UIã§ã®ãƒã‚¹ã‚­ãƒ³ã‚°æ¼ã‚Œä¿®æ­£

**äº’æ›æ€§ã®æ³¨æ„**:
1. **scikit-learn**: v1.7.*ã§ã®ã¿å‹•ä½œä¿è¨¼
2. **fugashi**: v1.3.*ã«å›ºå®šï¼ˆãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¤‰æ›´ä¸å¯ï¼‰
3. **æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: UTF-8ã®ã¿ï¼ˆBOMç„¡ã—ï¼‰

### B. è©³ç´°ä»•æ§˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³

#### B.1 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹<br/>raw/JSONL] -->|æ­£è¦åŒ–| B[vector_pretrainer]
    B -->|å­¦ç¿’| C[tfidf_vectorizer.joblib<br/>+ metadata.json]
    C -->|ã‚³ãƒ”ãƒ¼| D[model/vectorizers/]
    D -->|èª­ã¿è¾¼ã¿| E[JAIML v3.3]
    
    F[config/global.yaml] -->|è¨­å®šå‚ç…§| B
    F -->|è¨­å®šå‚ç…§| E
    F -->|è¨­å®šå‚ç…§| G[lexicon_expansion]
    
    H[config/tfidf_config.yaml] -->|TF-IDFè¨­å®š| B
    H -->|TF-IDFè¨­å®š| E
    
    I[lexicons/jaiml_lexicons.yaml] -->|è¾æ›¸å‚ç…§| E
    I -->|è¾æ›¸å‚ç…§| G
    
    J[å¯¾è©±ãƒ‡ãƒ¼ã‚¿] -->|å…¥åŠ›| E
    E -->|åˆ†æçµæœ| K[JSONå‡ºåŠ›]
    
    L[ã‚³ãƒ¼ãƒ‘ã‚¹] -->|å€™è£œæŠ½å‡º| G
    G -->|è¾æ›¸æ›´æ–°| I
    G -->|å¼±æ•™å¸«ãƒ‡ãƒ¼ã‚¿| M[å­¦ç¿’ãƒ‡ãƒ¼ã‚¿]
```

**ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®è©³ç´°**:

1. **TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã®ç”Ÿæˆãƒ•ãƒ­ãƒ¼**:
   - `vector_pretrainer`ãŒå¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’èª­ã¿è¾¼ã¿
   - `config/tfidf_config.yaml`ã®è¨­å®šã«å¾“ã£ã¦å­¦ç¿’
   - `.joblib`å½¢å¼ã§ä¿å­˜ã€`metadata.json`ã§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
   - `model/vectorizers/`ã«æ‰‹å‹•ã‚³ãƒ”ãƒ¼å¾Œã€å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå‚ç…§

2. **è¾æ›¸æ‹¡å¼µãƒ•ãƒ­ãƒ¼**:
   - `lexicon_expansion`ãŒã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰å€™è£œã‚’è‡ªå‹•æŠ½å‡º
   - äººæ‰‹æ¤œè¨¼ã‚’çµŒã¦`jaiml_lexicons.yaml`ã‚’æ›´æ–°
   - ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«ã‚ˆã‚Šå·®åˆ†ã‚’è¿½è·¡

3. **è¿åˆæ€§åˆ†æãƒ•ãƒ­ãƒ¼**:
   - `JAIML v3.3`ãŒå¯¾è©±ãƒšã‚¢ã‚’å—ã‘å–ã‚Š
   - è¾æ›¸ãƒãƒƒãƒãƒ³ã‚°ã¨TF-IDFç‰¹å¾´é‡ã‚’å«ã‚€12æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
   - 4ãƒ˜ãƒƒãƒ‰MLPã«ã‚ˆã‚Š4ã‚«ãƒ†ã‚´ãƒªã®ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º

#### B.2 å…±é€šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ä»•æ§˜

##### B.2.1 config/global.yamlå®Œå…¨ä»•æ§˜

```yaml
# JAIMLçµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…±é€šè¨­å®š v1.0
# ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã™ã‚‹

# åŸºæœ¬è¨­å®š
common:
  tokenizer: fugashi        # å½¢æ…‹ç´ è§£æå™¨ï¼ˆå¤‰æ›´ä¸å¯ï¼‰
  encoding: utf-8          # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
  random_seed: 42          # å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰
  log_level: INFO          # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«

# TF-IDFå…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
tfidf:
  min_df: 1                # æœ€å°æ–‡æ›¸é »åº¦
  max_df: 0.95             # æœ€å¤§æ–‡æ›¸é »åº¦ï¼ˆ95%ä»¥ä¸Šã§å‡ºç¾ã™ã‚‹èªã‚’é™¤å¤–ï¼‰
  ngram_range: [1, 1]      # å˜èªå˜ä½ï¼ˆunigramï¼‰

# ãƒ‘ã‚¹è¨­å®š
paths:
  # ãƒ¢ãƒ‡ãƒ«é–¢é€£
  vectorizer_path: model/vectorizers/tfidf_vectorizer.joblib
  model_path: model/jaiml_v3_3/ingratiation_model.pt
  
  # è¾æ›¸é–¢é€£
  lexicon_path: lexicons/jaiml_lexicons.yaml
  lexicon_versions: lexicons/versions/
  
  # ã‚³ãƒ¼ãƒ‘ã‚¹é–¢é€£
  corpus_raw: corpus/raw/
  corpus_jsonl: corpus/jsonl/
  
  # å‡ºåŠ›é–¢é€£
  output_dir: outputs/
  log_dir: logs/

# å‡¦ç†åˆ¶é™
limits:
  max_text_length: 10000   # æœ€å¤§æ–‡å­—æ•°
  min_text_length: 5       # æœ€å°æ–‡å­—æ•°
  batch_size: 1000         # ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º
  max_memory_gb: 4         # æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

# CI/CDè¨­å®š
ci:
  coverage_threshold: 80   # ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸é–¾å€¤ï¼ˆ%ï¼‰
  max_complexity: 10       # å¾ªç’°çš„è¤‡é›‘åº¦ã®ä¸Šé™
  timeout_seconds: 600     # CIå®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
```

##### B.2.2 config/tfidf_config.yamlå®Œå…¨ä»•æ§˜

```yaml
# TF-IDFè©³ç´°è¨­å®š
# global.yamlã®å€¤ã‚’ç¶™æ‰¿ã—ã€TF-IDFå›ºæœ‰ã®è¨­å®šã‚’è¿½åŠ 

# global.yamlã‹ã‚‰ã®ç¶™æ‰¿ï¼ˆCIæ¤œè¨¼å¯¾è±¡ï¼‰
tokenizer: fugashi
min_df: 1
max_df: 0.95
ngram_range: [1, 1]

# ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼è¨­å®š
token_normalization: NFKC   # Unicodeæ­£è¦åŒ–å½¢å¼

# TF-IDFè¨ˆç®—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
tfidf_params:
  sublinear_tf: true       # TFå€¤ã®å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
  use_idf: true           # IDFé‡ã¿ä»˜ã‘ã®ä½¿ç”¨
  smooth_idf: true        # ã‚¼ãƒ­é™¤ç®—å›é¿ã®ãŸã‚ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
  norm: l2                # L2æ­£è¦åŒ–

# å‰å‡¦ç†è¨­å®š
preprocessing:
  lowercase: false        # æ—¥æœ¬èªã§ã¯ä¸ä½¿ç”¨
  strip_accents: null     # ã‚¢ã‚¯ã‚»ãƒ³ãƒˆé™¤å»ãªã—
  analyzer: word          # å˜èªå˜ä½ã®åˆ†æ
  stop_words: null        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãªã—ï¼ˆæ—¥æœ¬èªï¼‰

# ä¿å­˜è¨­å®š
output:
  compress_level: 3       # joblibåœ§ç¸®ãƒ¬ãƒ™ãƒ«ï¼ˆ0-9ï¼‰
  save_metadata: true     # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
  
# å­¦ç¿’è¨­å®š
training:
  max_features: null      # èªå½™ã‚µã‚¤ã‚ºä¸Šé™ãªã—
  binary: false           # ãƒã‚¤ãƒŠãƒªé‡ã¿ä»˜ã‘ãªã—
```

#### B.3 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨å†ç¾æ€§ã®è©³ç´°å®Ÿè£…

##### B.3.1 Pickleä½¿ç”¨ç¦æ­¢ã®å®Ÿè£…

```python
import warnings
import joblib
import os

class SecurityManager:
    @staticmethod
    def save_model_safe(model, path: str, metadata: Dict[str, Any]) -> None:
        """å®‰å…¨ãªãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        if path.endswith('.pkl') or path.endswith('.pickle'):
            raise ValueError(
                "Pickle format is prohibited due to security risks. "
                "Use joblib format instead."
            )
        
        # joblibå½¢å¼ã§ä¿å­˜
        joblib.dump(model, path, compress=3)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        metadata_path = path.replace('.joblib', '_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
    
    @staticmethod
    def load_model_safe(path: str) -> Any:
        """å®‰å…¨ãªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        if not path.endswith('.joblib'):
            warnings.warn(
                "Non-joblib format detected. This may pose security risks.",
                SecurityWarning
            )
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
        metadata_path = path.replace('.joblib', '_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path) as f:
                metadata = json.load(f)
            
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¤œè¨¼
            VersionValidator.validate_sklearn_version(metadata)
        
        return joblib.load(path)
```

##### B.3.2 å†ç¾æ€§ä¿è¨¼ã®å®Ÿè£…

```python
import random
import numpy as np
import os
import hashlib

class ReproducibilityManager:
    @staticmethod
    def ensure_reproducibility(seed: int = 42) -> None:
        """å®Œå…¨ãªå†ç¾æ€§ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã®ç’°å¢ƒè¨­å®š"""
        # Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        random.seed(seed)
        
        # NumPy
        np.random.seed(seed)
        
        # ç’°å¢ƒå¤‰æ•°
        os.environ['PYTHONHASHSEED'] = str(seed)
        
        # ä¸¦åˆ—å‡¦ç†ã®åˆ¶å¾¡
        os.environ['OMP_NUM_THREADS'] = '1'
        os.environ['MKL_NUM_THREADS'] = '1'
        os.environ['NUMEXPR_NUM_THREADS'] = '1'
        
        # PyTorchï¼ˆä½¿ç”¨ã™ã‚‹å ´åˆï¼‰
        try:
            import torch
            torch.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
        except ImportError:
            pass
    
    @staticmethod
    def compute_data_hash(data: Any) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
        if isinstance(data, str):
            return hashlib.sha256(data.encode()).hexdigest()
        elif isinstance(data, dict):
            # è¾æ›¸ã¯é †åºã‚’ä¿è¨¼ã—ã¦JSONåŒ–
            json_str = json.dumps(data, sort_keys=True)
            return hashlib.sha256(json_str.encode()).hexdigest()
        else:
            # ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿å‹
            return hashlib.sha256(str(data).encode()).hexdigest()
```

##### B.3.3 Pickleä½¿ç”¨æ™‚ã®è­¦å‘Šå®Ÿè£…

```python
import warnings
import pickle

def save_with_pickle_warning(data: Any, filepath: str) -> None:
    """Pickleä½¿ç”¨æ™‚ã«è­¦å‘Šã‚’å‡ºåŠ›ï¼ˆCIæº–æ‹ ï¼‰"""
    warnings.warn(
        "Using pickle format - trusted source only! "
        "Consider using joblib for better security.",
        SecurityWarning
    )
    
    with open(filepath, 'wb') as f:
        pickle.dump(data, f)
```

#### B.4 æ‹¡å¼µã‚«ãƒ†ã‚´ãƒªåˆ¶ç´„ä»•æ§˜

##### B.4.1 ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚­ãƒ¼ãƒå®šç¾©

```yaml
# config/category_schemas.yaml
categories:
  # 11æ—¢å®šã‚«ãƒ†ã‚´ãƒªï¼ˆæ‹¡å¼µä¸å¯ï¼‰
  template_phrases:
    extendable: false
    description: "å®šå‹è¡¨ç¾ãƒ»æ…£ç”¨å¥"
    required: true
  
  humble_phrases:
    extendable: false
    description: "è¬™éœãƒ»è‡ªå·±å‘ä¸‹è¡¨ç¾"
    required: true
  
  # ... ä»–ã®æ—¢å®šã‚«ãƒ†ã‚´ãƒª ...
  
  # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ†ã‚´ãƒªï¼ˆæ‹¡å¼µå¯èƒ½ï¼‰
  custom_category_1:
    extendable: true
    description: "ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã‚«ãƒ†ã‚´ãƒª"
    required: false
```

##### B.4.2 JAIMLå´ã®æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªå‡¦ç†

```python
class LexiconMatcher:
    def __init__(self, lexicon_path: str):
        self.lexicons = self._load_lexicon(lexicon_path)
        self.known_categories = set([
            'template_phrases', 'humble_phrases', 'achievement_nouns',
            'achievement_verbs', 'evaluative_adjectives', 'positive_emotion_words',
            'intensifiers', 'comparative_terms', 'contrastive_conjunctions',
            'modal_expressions', 'self_reference_words'
        ])
    
    def match(self, text: str) -> OrderedDict[str, List[str]]:
        """æ—¢çŸ¥ã‚«ãƒ†ã‚´ãƒªã®ã¿ãƒãƒƒãƒãƒ³ã‚°ã€æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯èª­ã¿é£›ã°ã™"""
        results = OrderedDict()
```

#### B.4 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ¼ãƒå®šç¾©

##### B.4.1 global_schema.yaml

```yaml
# config/global.yamlã®JSONSchemaå®šç¾©
type: object
required:
  - common
  - tfidf
  - paths
properties:
  common:
    type: object
    required:
      - tokenizer
      - encoding
    properties:
      tokenizer:
        type: string
        enum: ["fugashi"]  # å›ºå®šå€¤
      encoding:
        type: string
        enum: ["utf-8"]    # å›ºå®šå€¤
      random_seed:
        type: integer
        minimum: 0
      log_level:
        type: string
        enum: ["DEBUG", "INFO", "WARNING", "ERROR"]
  
  tfidf:
    type: object
    required:
      - min_df
      - max_df
      - ngram_range
    properties:
      min_df:
        type: integer
        minimum: 1
      max_df:
        type: number
        exclusiveMinimum: 0
        exclusiveMaximum: 1
      ngram_range:
        type: array
        items:
          type: integer
          minimum: 1
        minItems: 2
        maxItems: 2
  
  paths:
    type: object
    required:
      - vectorizer_path
      - lexicon_path
    patternProperties:
      ".*_path$|.*_dir$":
        type: string
```

#### B.5 ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ­ã‚®ãƒ³ã‚°ä»•æ§˜

```python
import logging
from typing import Optional

class JAIMLException(Exception):
    """JAIMLåŸºåº•ä¾‹å¤–ã‚¯ãƒ©ã‚¹"""
    pass

class ConfigurationError(JAIMLException):
    """è¨­å®šé–¢é€£ã‚¨ãƒ©ãƒ¼"""
    pass

class DataValidationError(JAIMLException):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼"""
    pass

class VersionMismatchError(JAIMLException):
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆã‚¨ãƒ©ãƒ¼"""
    pass

class LoggingManager:
    @staticmethod
    def setup_logging(config_path: str = "config/global.yaml") -> logging.Logger:
        """çµ±ä¸€ãƒ­ã‚®ãƒ³ã‚°è¨­å®š"""
        config = ConfigManager(config_path)
        log_config = config.get_common_config()
        
        logging.basicConfig(
            level=getattr(logging, log_config.get('log_level', 'INFO')),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        logger = logging.getLogger('JAIML')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ã®è¿½åŠ 
        log_dir = config.get_paths()['log_dir']
        os.makedirs(log_dir, exist_ok=True)
        
        fh = logging.FileHandler(
            os.path.join(log_dir, f'jaiml_{datetime.now():%Y%m%d}.log')
        )
        fh.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        logger.addHandler(fh)
        
        return logger
```

#### B.6 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆä»•æ§˜

```python
import pytest
from typing import Dict, Any

class IntegrationTestSuite:
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def setup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        ReproducibilityManager.ensure_reproducibility()
        
        # ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã®èª­ã¿è¾¼ã¿
        config = ConfigManager("config/test_config.yaml")
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        test_dirs = ['test_corpus', 'test_outputs', 'test_models']
        for dir_name in test_dirs:
            os.makedirs(dir_name, exist_ok=True)
        
        yield config
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for dir_name in test_dirs:
            shutil.rmtree(dir_name, ignore_errors=True)
    
    def test_end_to_end_pipeline(self, setup_test_environment):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        config = setup_test_environment
        
        # 1. TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã®å­¦ç¿’
        trainer = TFIDFTrainer(config.get_tfidf_config_path())
        trainer.train("test_corpus/sample.jsonl")
        model_paths = trainer.save("test_models/")
        
        assert os.path.exists(model_paths['model'])
        assert os.path.exists(model_paths['metadata'])
        
        # 2. è¾æ›¸æ‹¡å¼µã®å®Ÿè¡Œ
        extractor = CandidateExtractor(config.get_extraction_rules_path())
        candidates = extractor.extract_category(
            "test_corpus/sample.jsonl", 
            "template_phrases"
        )
        
        assert len(candidates) > 0
        
        # 3. JAIMLåˆ†æã®å®Ÿè¡Œ
        analyzer = JAIMLAnalyzer(
            model_path="test_models/jaiml_model.pt",
            lexicon_path=config.get_lexicon_path(),
            vectorizer_path=model_paths['model']
        )
        
        result = analyzer.analyze(
            user="ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±",
            response="ãƒ†ã‚¹ãƒˆAIå¿œç­”"
        )
        
        assert 'scores' in result
        assert all(0 <= result['scores'][cat] <= 1 
                  for cat in ['social', 'avoidant', 'mechanical', 'self'])
```

#### B.7 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ä»•æ§˜

```python
from concurrent.futures import ProcessPoolExecutor
import multiprocessing as mp

class PerformanceOptimizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def optimize_batch_processing(data: List[Dict], 
                                 processor_func: callable,
                                 batch_size: int = 1000,
                                 n_workers: Optional[int] = None) -> List[Any]:
        """ãƒãƒƒãƒå‡¦ç†ã®æœ€é©åŒ–"""
        if n_workers is None:
            n_workers = mp.cpu_count() - 1
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒã«åˆ†å‰²
        batches = [data[i:i+batch_size] for i in range(0, len(data), batch_size)]
        
        # ä¸¦åˆ—å‡¦ç†
        with ProcessPoolExecutor(max_workers=n_workers) as executor:
            results = list(executor.map(processor_func, batches))
        
        # çµæœã®çµåˆ
        return [item for batch_result in results for item in batch_result]
    
    @staticmethod
    def cache_manager(cache_size: int = 1000):
        """LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
        from functools import lru_cache
        return lru_cache(maxsize=cache_size)
```

#### B.8 æ‹¡å¼µè¨ˆç”»ã®è©³ç´°

##### B.8.1 v1.2: BERTãƒ™ãƒ¼ã‚¹åŸ‹ã‚è¾¼ã¿å¯¾å¿œ

```python
class BERTVectorizer:
    """å°†æ¥å®Ÿè£…ï¼šBERTåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼"""
    
    def __init__(self, model_name: str = "cl-tohoku/bert-base-japanese"):
        self.model_name = model_name
        # å®Ÿè£…äºˆå®š
    
    def fit_transform(self, corpus: List[str]) -> np.ndarray:
        """BERTã«ã‚ˆã‚‹æ–‡åŸ‹ã‚è¾¼ã¿ã®ç”Ÿæˆ"""
        # å®Ÿè£…äºˆå®š
        pass
```

##### B.8.2 v1.3: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´é‡

```python
class MultimodalFeatureExtractor:
    """å°†æ¥å®Ÿè£…ï¼šãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´æŠ½å‡º"""
    
    def extract_features(self, text: str, audio: Optional[np.ndarray] = None,
                        video: Optional[np.ndarray] = None) -> Dict[str, float]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ»éŸ³å£°ãƒ»æ˜ åƒã‹ã‚‰ã®çµ±åˆç‰¹å¾´æŠ½å‡º"""
        # å®Ÿè£…äºˆå®š
        pass
```

##### B.8.3 v2.0: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–API

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# å°†æ¥å®Ÿè£…ï¼šFastAPIã«ã‚ˆã‚‹REST API
app = FastAPI(title="JAIML API", version="2.0")

class AnalysisRequest(BaseModel):
    user: str
    response: str

class AnalysisResponse(BaseModel):
    scores: Dict[str, float]
    category: str
    index: float
    confidence: float

@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_dialogue(request: AnalysisRequest):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¿åˆæ€§åˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    # å®Ÿè£…äºˆå®š
    pass
```